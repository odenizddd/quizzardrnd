{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to export several csv files for different parts of speech. (Nouns, verbs, adjectives, and adverbs.) Each file will list words from the most common to the least common and associate each word with a difficulty score.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "Pandas\n",
    "WordNet\n",
    "Wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ozgurdenizdemir/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/ozgurdenizdemir/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run once\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordfreq import word_frequency\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_diff_score(freq):\n",
    "    return -math.log(freq, 10) - 1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postags(word):\n",
    "    # Retrieve synsets for the word\n",
    "    synsets = wn.synsets(word)\n",
    "    \n",
    "    # Extract unique POS tags from synsets\n",
    "    pos_tags = {synset.pos() for synset in synsets}  # Use a set to avoid duplicates\n",
    "    \n",
    "    return \", \".join(list(pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = words.words()\n",
    "# print(len(all_wordnet_words))\n",
    "all_words = { word.lower() for word in all_words if word_frequency(word, 'en') > 0 }\n",
    "# print(len(all_wordfreq_words))\n",
    "all_words = [(word, get_diff_score(word_frequency(word, 'en')), get_postags(word)) for word in all_wordfreq_words]\n",
    "all_words.sort(key=lambda x:x[1])\n",
    "\n",
    "word = [word for word, score, postags in all_words]\n",
    "score = [score for word, score, postags in all_words]\n",
    "postags = [postags for word, score, postags in all_words]\n",
    "corpus = pd.DataFrame({'word': word, 'score': score, 'postags': postags})\n",
    "\n",
    "corpus.to_csv(\"../data/corpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65045\n"
     ]
    }
   ],
   "source": [
    "corpus = pd.read_csv(\"../data/corpus.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
